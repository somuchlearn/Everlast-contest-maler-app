# ğŸ¨ MalerVoice AI

**Intelligente Angebotserstellung fÃ¼r Maler â€“ per Sprache und Text**

> ğŸ† Eingereicht fÃ¼r den Developer Contest: Voice-to-Text Desktop App

---

## ğŸ¯ Das Problem

**Maler und Handwerker verlieren tÃ¤glich 1-2 Stunden mit Angebotserstellung.**

Der typische Ablauf heute:
1. Kunde anrufen / Vor-Ort-Termin
2. Notizen auf Papier oder Handy
3. ZurÃ¼ck ins BÃ¼ro
4. Fotos durchschauen
5. FlÃ¤chen berechnen
6. Preise nachschlagen
7. Angebot in Word/Excel tippen
8. PDF erstellen und versenden

**Das Ergebnis:** FehleranfÃ¤llig, zeitaufwÃ¤ndig, frustrierend.

---

## ğŸ’¡ Die LÃ¶sung

**MalerVoice AI** transformiert den gesamten Prozess in einen einzigen, nahtlosen Workflow:

```
ğŸ¤ Sprache  +  ğŸ“¸ Fotos  +  ğŸ“ Text  â†’  ğŸ¤– KI (lokal oder Cloud)  â†’  ğŸ“„ Fertiges Angebot
```

### So funktioniert's:

1. **Hotkey drÃ¼cken** (`âŒ˜â‡§R`) â€“ App ist sofort bereit
2. **Sprechen**: *"Wohnzimmer 25 Quadratmeter, WÃ¤nde und Decke streichen, drei Fenster, Risse in der SÃ¼dwand"*
3. **Optional**: Fotos vom Raum hinzufÃ¼gen
4. **Ein Klick** â†’ VollstÃ¤ndiges Angebot mit:
    - Detaillierten Positionen
    - Korrekten Preisen (nach Handwerksstandard)
    - Professioneller KI-Analyse
    - PDF-Export

**Zeitersparnis: 45-60 Minuten pro Angebot.**

---

## âœ¨ Features

| Feature | Beschreibung |
|---------|-------------|
| ğŸ¤ **Voice-to-Text** | Online: OpenAI Whisper API Â· Offline: lokaler Whisper im Browser (WASM) |
| ğŸ“¸ **Foto-Analyse** | Online: Bilder werden per n8n an Google Gemini gesendet fÃ¼r visuelle Kalkulation |
| âŒ¨ï¸ **Global Hotkey** | `âŒ˜â‡§R` / `Ctrl+Shift+R` â€“ funktioniert aus jeder Anwendung |
| ğŸ¤– **KI-Enrichment** | Online: n8n + Gemini Â· Offline: Ollama (Mistral) mit OpenAI-Fallback |
| ğŸ”„ **Online/Offline** | Ein Toggle wechselt zwischen Cloud- und lokal-Modus |
| ğŸ“„ **PDF-Export** | Professionelle Angebote, sofort versandfertig |
| ğŸŒ™ **Dark Mode UI** | Modernes, augenschonendes Design |

---

## ğŸ—ï¸ Architektur

![Architektur](docs/architektur.svg)

### Technologie-Stack

| Komponente | Technologie | Warum? |
|------------|-------------|--------|
| **Desktop Runtime** | Tauri 2.0 + Rust | Schnell, sicher, klein (~10MB vs ~150MB Electron) |
| **Framework** | Next.js 15 + React 19 | Statischer Export fÃ¼r Tauri, moderna Komponentenstruktur |
| **Voice (Offline)** | Whisper via @huggingface/transformers | LÃ¤uft lokal im Browser (WASM), keine API nÃ¶tig |
| **Voice (Online)** | OpenAI Whisper API | Schnellere Transkription, kein lokaler Modell-Download |
| **Enrichment (Offline)** | Ollama (Mistral) | Lokales Modell, OpenAI-kompatibler API |
| **Enrichment (Online)** | n8n + Google Gemini | Bildanalyse via Gemini, orchestriert durch n8n-Workflow |
| **Fallback** | OpenAI GPT-4o | Backup wenn Ollama nicht verfÃ¼gbar |
| **PDF-Generation** | jsPDF | Client-seitig, keine Server-AbhÃ¤ngigkeit |

---

## ğŸ”„ Datenfluss

```
â”€â”€ ONLINE-Modus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sprache â”‚â”€â”€â–º â”‚ OpenAI Whisper  â”‚â”€â”€â–º Transkript â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚      API        â”‚                 â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
                                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fotos   â”‚â”€â”€â–º (FormData Binary) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ n8n       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚ Webhook   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚    â†“      â”‚
â”‚   Text   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚ Gemini    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚ (Analyse) â”‚
                                             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                                   â”‚
â”€â”€ OFFLINE-Modus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  Sprache â”‚â”€â”€â–º â”‚ Whisper (lokal) â”‚â”€â”€â–º Transkript â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ @huggingface/   â”‚                â”‚
                â”‚ transformers    â”‚                â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Text   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚  Ollama   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚ (Mistral) â”‚
                                             â”‚  oder     â”‚
                                             â”‚  OpenAI   â”‚
                                             â”‚  Fallback â”‚
                                             â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                                   â”‚
â”€â”€ Gemeinsam â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF    â”‚ â—„â”€â”€â”€ â”‚  UI      â”‚ â—„â”€â”€â”€ â”‚  Parse   â”‚â—„â”€â”‚  JSON    â”‚
â”‚  Export  â”‚      â”‚  Render  â”‚      â”‚  + Calc  â”‚  â”‚ Response â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Installation & Setup

### Voraussetzungen

- Node.js 18+
- Rust (via rustup)
- [Ollama](https://ollama.ai) installiert
- macOS / Windows / Linux

### 1. Repository klonen

```bash
git clone https://github.com/somuchlearn/Everlast-contest-maler-app.git
cd Everlast-contest-maler-app
```

### 2. Ollama-Modell pullen *(nur fÃ¼r Offline-Modus)*

```bash
ollama pull mistral
```

> Das Modell (~4GB) wird einmal heruntergeladen und lokal gespeichert. Ollama muss beim Betrieb im Hintergrund laufen. Im Online-Modus wird Ollama nicht benÃ¶tigt.

### 3. Dependencies installieren

```bash
npm install
```

### 4. Environment konfigurieren (optional)

Erstelle `.env` im Root-Verzeichnis fÃ¼r den Cloud-Fallback:

```env
NEXT_PUBLIC_OPENAI_API_KEY=sk-your-openai-api-key
```

> Ohne diesen Key lÃ¤uft die App trotzdem â€“ solange Ollama lokal lÃ¤uft, wird OpenAI nicht benÃ¶tigt.

### 5. Development starten

```bash
npm run tauri dev
```

### 6. Production Build

```bash
npm run tauri build
```

Das Build-Artefakt liegt in `src-tauri/target/release/bundle/`.

> **Im Offline-Modus** wird beim ersten Umschalten das Whisper-Modell (~244MB) automatisch heruntergeladen und gecacht. Danach lÃ¤uft die Transkription komplett ohne Internet.

---

## âŒ¨ï¸ Bedienung

| Aktion | Shortcut / UI |
|--------|---------------|
| Online/Offline wechseln | Toggle-Schalter im Header (ğŸ–¥ï¸ â†” â˜ï¸) |
| App aktivieren | `âŒ˜â‡§R` (Mac) / `Ctrl+Shift+R` (Win/Linux) |
| Aufnahme starten | Button "ğŸ™ï¸ Aufnahme starten" oder Hotkey |
| Aufnahme stoppen | Button "Aufnahme stoppen" oder Hotkey erneut |
| Fotos hinzufÃ¼gen | Drag & Drop oder Klick auf Upload-Zone |
| Angebot erstellen | Button "Angebot erstellen â†’" |
| PDF exportieren | Button "ğŸ“„ PDF" im Ergebnis |
| Neues Angebot | Button "â†º Neu" |

---

## ğŸ¨ Design-Entscheidungen

### 1. Warum Tauri statt Electron?

| Kriterium | Tauri | Electron |
|-----------|-------|----------|
| Bundle-GrÃ¶ÃŸe | ~10 MB | ~150 MB |
| RAM-Verbrauch | ~50 MB | ~300 MB |
| Startup-Zeit | <1s | 2-3s |
| Sicherheit | Rust-basiert | Chromium-basiert |

**Fazit:** FÃ¼r eine App die "nahtlos im Workflow" sein soll, ist Performance entscheidend.

### 2. Warum Online/Offline-Toggle statt rein Cloud oder rein lokal?

Das Briefing fordert eine **"eigenstÃ¤ndige Desktop-Applikation"** â€” das erfordert Funktionieren ohne Internet. Gleichzeitig bietet Cloud-KI konkrete Vorteile (Bildanalyse, Geschwindigkeit). Der Toggle gibt dem Nutzer die Kontrolle:

- **Offline-Modus:** Whisper lÃ¤uft Ã¼ber `@huggingface/transformers` direkt im Browser (WASM). Enrichment per Ollama (Mistral) lokal. Falls Ollama nicht verfÃ¼gbar â†’ automatischer Fallback auf OpenAI GPT-4o.
- **Online-Modus:** Transkription Ã¼ber OpenAI Whisper API. Enrichment Ã¼ber n8n-Workflow mit Google Gemini â€” hier kommt die Bildanalyse ins Spiel (sieh Punkt 3).
- **Pragmatische Entscheidung:** Wer Ollama nicht installieren kann oder will, kann trotzdem die vollen Features nutzen â€“ einfach auf Online bleiben.

### 3. Warum n8n + Google Gemini fÃ¼r Online-Enrichment?

Die Foto-Analyse war die technisch anspruchsvolste Anforderung. Optionen:

- **OpenAI Vision direkt:** Einfacher, aber kein Workflow-Management, kein Routing nach Medientyp.
- **n8n + Gemini (gewÃ¤hlt):** n8n orchestriert den gesamten Prozess â€” Routing nach `text_only` / `image_analysis` / `mixed_media`, unterschiedliche Gemini-Modelle je KomplexitÃ¤t (2.5 Pro fÃ¼r Text, 1.5 Pro fÃ¼r Multi-Modal). Die Bilder werden als `multipart/form-data` an den Webhook gesendet und landen direkt in n8n's Binary-Pipeline.

**Vorteil:** Der KI-Workflow kann unabhÃ¤ngig vom Frontend weiterentwickelt werden â€” neue Modelle, Prompts oder Routingregeln Ã¤ndern sich nur auf der n8n-Seite.

### 4. Warum Ollama + Mistral?

- **OpenAI-kompatibler API:** Der gleiche Code arbeitet mit Ollama lokal und OpenAI als Fallback â€“ minimale Duplikation.
- **Mistral:** Starkes Modell fÃ¼r Deutsch, verlÃ¤sslich bei strukturierter JSON-Ausgabe.
- **Einfaches Setup:** Ein Befehl (`ollama pull mistral`), dann lÃ¤uft es.

### 5. UI/UX Entscheidungen

- **Dark Mode:** Reduziert Augenbelastung bei lÃ¤ngerer Nutzung
- **Minimalistisches Design:** Fokus auf Funktion, keine Ablenkung
- **Inline-Feedback:** Status, Transkript, Fehler direkt sichtbar
- **Model-Status-Indikator:** Zeigt ob das Whisper-Modell geladen ist

---

## ğŸ“Š Beispiel-Output

**Eingabe (Sprache):**
> "Schlafzimmer 18 Quadratmeter, WÃ¤nde streichen weiÃŸ, Decke auch, ein Fenster, TÃ¼r, kleiner Riss an der Nordwand"

**Ausgabe:**

| Position | Menge | Einheit | Preis | Summe |
|----------|-------|---------|-------|-------|
| Abkleben Fenster, TÃ¼r | 2 | Stk | 4,50 â‚¬ | 9,00 â‚¬ |
| Risse ausbessern | 1 | Stk | 30,00 â‚¬ | 30,00 â‚¬ |
| Grundierung WÃ¤nde | 48 | mÂ² | 8,00 â‚¬ | 384,00 â‚¬ |
| Wandanstrich weiÃŸ 2-fach | 48 | mÂ² | 14,00 â‚¬ | 672,00 â‚¬ |
| Deckenanstrich weiÃŸ | 18 | mÂ² | 13,00 â‚¬ | 234,00 â‚¬ |
| **Netto** | | | | **1.329,00 â‚¬** |
| **MwSt. 19%** | | | | **252,51 â‚¬** |
| **Brutto** | | | | **1.581,51 â‚¬** |

---

## ğŸ™ Danksagungen

- [Tauri](https://tauri.app/) â€“ Desktop-Framework
- [Next.js](https://nextjs.org/) â€“ Web-Framework
- [@huggingface/transformers](https://github.com/huggingface/transformers.js) â€“ Lokale Whisper-Inferenz im Browser
- [Ollama](https://ollama.ai/) â€“ Lokale LLM-AusfÃ¼hrung
- [n8n](https://n8n.io/) â€“ Workflow-Orchestrierung fÃ¼r Online-Enrichment
- [Google Gemini](https://ai.google/) â€“ Cloud-KI fÃ¼r Text- und Bildanalyse
- [jsPDF](https://github.com/parallax/jsPDF) â€“ Client-seitige PDF-Generierung

---

<div align="center">

**ğŸ¨ MalerVoice AI** â€“ *Sprich dein Angebot.*

</div>
